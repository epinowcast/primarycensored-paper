---
title: "Modelling delays with primary Event Censored Distributions"
author:
  - name: Samuel P. C. Brand
    affiliations:
      - name: Center for Forecasting and Outbreak Analytics, Centers for Disease Control and Prevention, United States of America
    corresponding: true
  - name: Kelly Charniga
    affiliations:
      - name: Institut Pasteur, France
    corresponding: false
  - name: Sang Woo Park
    affiliations:
      - name: Department of Ecology and Evolution, University of Chicago, Chicago, Illinois, United States of America
    corresponding: false
  - name: James Mba Azam
    affiliations:
      - name: Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene & Tropical Medicine, London, United Kingdom
    corresponding: false
  - name: Adam Howes
    affiliations:
      - name: Center for Forecasting and Outbreak Analytics, Centers for Disease Control and Prevention, United States of America
    corresponding: false
  - name: Carl Pearson
    affiliations:
      - name: Affiliation
    corresponding: false
  - name: Sebastian Funk
    affiliations:
      - name: Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene & Tropical Medicine, London, United Kingdom
    corresponding: false
  - name: Sam Abbott
    affiliations:
      - name: Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene & Tropical Medicine, London, United Kingdom
    corresponding: false
    email: sam.abbott@lshtm.ac.uk
date: today
format:
  html:
    toc: false
    number-sections: false
bibliography: reference.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/plos.csl
---

## Abstract

## Author summary

## Introduction

Time-to-event distributions are essential in epidemiology, describing delays between events like infection and symptom onset. These inform disease natural history, enable nowcasting, and support epidemic reconstruction. However, real-world surveillance data present challenges due to censoring and truncation, which can significantly bias estimates if not properly addressed [@charniga2024best]. Inaccurate delay distributions directly impact critical response decisions during outbreaks, from resource allocation to intervention timing, potentially leading to mischaracterisation of epidemic dynamics and delayed public health actions [@Park2024.01.12.24301247].

A key challenge in epidemiological data is interval censoring, where event times are known only within specific intervals. Primary event censoring affects the initial event time (e.g., infection), secondary event censoring affects the end event time (e.g., symptom onset), and double interval censoring occurs when both are present [@charniga2024best; @Reich2009-aa]. These issues are compounded by right truncation, where events with longer delays are systematically missing from recent data because the secondary event hasn't yet occurred or been observed [@Park2024.01.12.24301247]. Each form of censoring introduces distinct biases that must be addressed for accurate estimation [@law1992effects].

Several approaches attempt to address these challenges, but each has limitations. Simple methods include discarding censored observations (infeasible when all data are censored) [@little2019statistical], discretisation (treating delays as occurring in fixed intervals), or fixed imputation (assuming events occur at interval midpoints). Park et al. found that treating unobserved primary event times as latent parameters proposed by Ward et al. improved upon fixed imputation [@Park2024.01.12.24301247; @Ward2022-wo], but this introduces N additional parameters when analysing N observations, limiting scalability to large datasets. Charniga et al. highlighted a persistent gap in computationally efficient methods for double interval censored data that maintain statistical rigour while scaling to large surveillance datasets [@charniga2024best].

In this paper, we aim to establish a standard approach for epidemiological delay distribution estimation that is statistically rigourous and computationally efficient. We extend Ward et al.'s method by marginalising over latent primary event times rather than treating them as individual parameters, maintaining statistical integrity while substantially improving scalability for large datasets. We first provide a general numerically solvable solution and then derive analytical solutions for common parametric distributions, including gamma, lognormal, and Weibull. We implement these methods in the open-source R package 'primarycensored' [@abbottprimarycensored], with both R functions and Stan extensions that integrate with existing tools like fitdistrplus and epidemiological modelling packages [@fitdistrplus; @stan; @abbottepinow2; @Cori2013]. In this paper, we present the statistical framework underlying our approach, derive analytical solutions for commonly used distributions, and evaluate our method using both simulated data and real-world case studies across a range of distributions. We first compare numerical accuracy and run time with the Ward et al. approach for recovering PMFs and then demonstrate parameter recovery versus a naive approach. Our method makes accurate delay distribution estimation feasible for large-scale surveillance datasets where previous approaches become computationally intractable. Our software tools enable using these approaches as part of more complex epidemiological models.

## Methods

### Statistical framework

#### Problem statement

For an individual, a primary event (e.g., infection) occurs at time $P_u$, followed by a secondary event (e.g., symptom onset) at time $S$. The true delay between these events is $T = S - P_u$, which follows some distribution $f_T(t)$ with cumulative distribution function $F_T(t)$. In practice, however, neither $P_u$ nor $S$ is typically observed.

Instead, we observe that the primary event occurred within a window $[t_P, t_P + w_P]$, where $w_P$ is the width of the primary censoring interval (often one day in surveillance data). Similarly, the secondary event is observed to occur within $[t_S, t_S + w_S]$, where $w_S$ is the width of the secondary censoring interval. The censored delay time, $T_c$, is measured from the end of the primary window to the end of the secondary window: $T_c = t_S + w_S - (t_P + w_P)$.

With non-informative censoring (where the observation process is independent of the actual event times), the distribution of the primary event within its window is:

$$f_P(p) = \frac{f_{P_u}(p)}{F_{P_u}(t_P + w_P) - F_{P_u}(t_P)}, \quad p \in [t_P, t_P + w_P]$$

In the simplest case, primary events occur uniformly within their censoring windows, but in real epidemiological situations, they often follow non-uniform patterns. During epidemic growth, for example, events are more likely to occur near the end of their censoring windows, while during decline, they are more likely to occur near the beginning. This can be modeled using an exponentially tilted distribution:

$$f_P(t) \propto \exp(r t) \mathbb{1}_{[t_P, t_P + w_P]}(t)$$

where $r$ controls the growth/decline rate.

The observed data are further complicated by right truncation. At any observation time $D$, we can only observe delays where the secondary event has already occurred. Delays longer than $D - P_u$ are systematically missing from the data, creating a bias toward shorter delays in recent data. This truncation effect is particularly important in real-time analyses during outbreaks, when recent primary events with longer delays are not yet observed.

#### Generative process for delay data

The generative process for generating delay data we consider in this paper follows these steps:

1. Generate a primary event time $P_u$ from its distribution $f_{P_u}(p)$
2. Generate a delay $T$ from the delay distribution $f_T(t)$
3. Calculate the secondary event time as $S = P_u + T$
4. Apply censoring by observing only that $P_u \in [t_P, t_P + w_P]$ and $S \in [t_S, t_S + w_S]$
5. Apply right truncation by excluding any observations where $S > D$ (where $D$ is the maximum observable time)

This then results in a empirical probability mass function (PMF) of delay data that is a combination of the true delay distribution $f_T(t)$ and the censoring and truncation processes. The primary goal of our method is to recover the true delay distribution $f_T(t)$ from censored and truncated observations, accounting for these various biases. The Ward et al. approach deals with modelling this sampling process by directly recreating it as a latent variable in the model [@Park2024.01.12.24301247; @Ward2022-wo].

### Solving the censoring problem

#### Double censored and right truncated PMF

To recover the true delay distribution $f_T(t)$ from observed data, we begin by considering the simplest case of secondary event censoring with right truncation, and then extend to include primary event censoring.

When only the secondary event is interval-censored, our goal is to calculate the probability that a delay falls into a specific observed bin. For a secondary event observed in the interval $[t_S, t_S + w_S]$ given that the primary event occurred at a precisely known time $P_u = t_P$, and conditioned on the secondary event occurring before the maximum observable time $D$, the PMF is:

$$P(T_c = t_S + w_S - t_P \mid \text{observed}) = \frac{P(S \in [t_S, t_S + w_S] \mid P_u = t_P)}{P(S < D \mid P_u = t_P)}$$

This can be written in terms of the CDF of the true delay distribution $F_T$:

$$P(T_c = t_S + w_S - t_P \mid \text{observed}) = \frac{F_T(t_S + w_S - t_P) - F_T(t_S - t_P)}{F_T(D - t_P)}$$

However, in most epidemiological contexts, the primary event is also interval-censored, creating double interval censoring. Following the approach of Park et al. [@Park2024.01.12.24301247], we treat the primary and secondary censoring as separable problems, rather than using the joint interval approach described by Reich et al. [@Reich2009-aa]. This separation significantly simplifies the mathematical formulation.

With primary event censoring, the primary event is known only to have occurred within the interval $[t_P, t_P + w_P]$. To account for this additional uncertainty, we need to derive the distribution of delays when the primary event is interval-censored. We introduce $F_{\text{cens}}(q)$ as the cumulative distribution function (CDF) of the delay distribution adjusted for primary event censoring:

$$F_{\text{cens}}(q) = P(T \leq q \mid P \in [t_P, t_P + w_P])$$

Once we have $F_{\text{cens}}$, we can extend our formula for secondary event censoring by substituting $F_{\text{cens}}$ for $F_T$:

$$P(T_c = t_S + w_S - (t_P + w_P) \mid \text{observed}) = \frac{F_{\text{cens}}(t_S + w_S - t_P) - F_{\text{cens}}(t_S - t_P)}{F_{\text{cens}}(D - t_P)}$$

which is equivalent to,

$$P(T_c = t_S + w_S - (t_P + w_P) \mid \text{observed}) = \frac{P(S \in [t_S, t_S + w_S] \mid P \in [t_P, t_P + w_P])}{P(S < D \mid P \in [t_P, t_P + w_P])}$$

This approach breaks the problem of double censoring and right truncation into separable components, with the primary censored CDF ($F_{\text{cens}}$) as the core element that needs to be derived. In the next section, we focus on deriving the primary censored distribution $F_{\text{cens}}$.

#### Primary event censored distributions

Having established the importance of the primary censored CDF ($F_{\text{cens}}$) in the previous section, we now focus on deriving this distribution.

The primary event censored CDF, $F_{\text{cens}}(q)$, represents the probability that the delay is less than or equal to $q$, given that the primary event occurred within its censoring window. By the law of total probability, we can decompose this conditional probability by considering all possible specific times where the primary event might have occurred within the censoring window:

$$F_{\text{cens}}(q) = P(T \leq q \mid P \in [t_P, t_P + w_P])$$

This can be formulated as an expectation over all possible primary event times, essentially calculating a weighted average where each possible primary event time is weighted by its probability:

$$F_{\text{cens}}(q) = \mathbb{E}_{P}[P(T \leq q \mid P)]$$

For continuous random variables, expectations are calculated using integrals. This gives us:

$$F_{\text{cens}}(q) = \int_{t_P}^{t_P + w_P} P(T \leq q \mid P = p) \cdot f_P(p) \, dp$$

where $f_P$ is the PDF of the primary event within its censoring window.

For a primary event occurring at time $p$, the true delay between this event and a secondary event occurring at time $t_P + q$ is $(t_P + q - p)$. Therefore, the conditional probability is:

$$P(T \leq q \mid P = p) = F_T(t_P + q - p)$$

where $F_T$ is the CDF of the true delay distribution. Substituting this into our integral:

$$F_{\text{cens}}(q) = \int_{t_P}^{t_P + w_P} F_T(t_P + q - p) \cdot f_P(p) \, dp$$

For computational simplicity, we can shift the integration variable to measure time from the start of the primary event window. Using the substitution $u = p - t_P$ (time since the start of the window):

$$F_{\text{cens}}(q) = \int_{0}^{w_P} F_T(q - u) \cdot f_P(t_P + u) \, du$$

This formulation gives us a general solution for the primary censored CDF that properly accounts for the uncertainty in the primary event time. We can use numerical integration to evaluate this integral for any delay distribution, or derive analytical solutions for specific parametric distributions, as we will explore in the next section. See the SI for an alternative treatment based on the survival functions and connections to the approaches of Park et al. [@Park2024.01.12.24301247], Reich et al. [@Reich2009-aa], and Cori et al. [@Cori2013].

### Analytical solutions

#### Exponentially tilted primary event times

In practice, censoring patterns can be complex, influenced by a variety of factors including circadian rhythms, weekday/weekend reporting differences, and changing epidemic dynamics. We simplify this complexity by modeling the primary event distribution within its censoring window using an exponentially tilted distribution:

$$f_P(t) \propto \exp(r t) \mathbb{1}_{[t_P, t_P + w_P]}(t)$$

where $r$ controls the growth rate (positive values) or decay rate (negative values) of events within the window. This captures the key feature that during epidemic growth, events are more likely to occur near the end of their censoring windows, while during decline, they occur closer to the beginning.

#### Uniform primary event time as a special case

When $r = 0$, the exponentially tilted distribution reduces to the uniform distribution:

$$f_P(t) = \frac{1}{w_P} \mathbb{1}_{[t_P, t_P + w_P]}(t)$$

In this case, our primary censored CDF integral simplifies to:

$$F_{\text{cens}}(q) = \int_{0}^{w_P} F_T(q - u) \cdot \frac{1}{w_P} \, du = \frac{1}{w_P} \int_{0}^{w_P} F_T(q - u) \, du$$

This integral can be evaluated using integration by parts, transforming it into:

$$F_{\text{cens}}(q) = F_T(q) + \frac{1}{w_P} \left[ \int_q^{q+w_P} f_T(z) (z-q) \, dz \right]$$

#### The role of partial expectation in analytical solutions

Here, we encounter what's known as the partial expectation of the delay distribution:

$$\int_q^{q+w_P} z \cdot f_T(z) \, dz$$

This partial expectation calculates the mean contribution from values within the interval [q, q+w_P]. This relationship enables us to develop analytical solutions that avoid numerical integration for distributions with closed-form partial expectations.

#### Distributions with analytical solutions

We have derived analytical solutions for several commonly used distributions:

- **Gamma distribution** with shape $k$ and scale $\theta$: The partial expectation equals $k\theta$ times the CDF of a Gamma(k+1,θ) distribution evaluated over the same interval.

- **Lognormal distribution** with location $\mu$ and scale $\sigma$: The partial expectation equals $e^{\mu+\sigma^2/2}$ times the CDF of a Lognormal(μ+σ²,σ) distribution over the same interval.

- **Weibull distribution** with shape $k$ and scale $\lambda$: The partial expectation relates to incomplete gamma functions through variable substitution.

- **Exponential distribution** as a special case of both Gamma and Weibull distributions with simpler forms.

The complete mathematical derivations are provided in the Supporting Information.

### Software implementation

#### R interface

The `primarycensored` R package implements the analytical and numerical solutions described in previous sections. The package follows R's standard distribution function pattern with density, distribution, quantile, and random generation functions that mirror base R naming conventions. The core functionality is implemented as S3 methods, enabling straightforward extension with new analytical solutions. The interface supports arbitrary delay distributions through their distribution functions (e.g., `lnorm` for lognormal) and includes optimised analytical implementations for gamma, lognormal, and Weibull distributions with uniform primary event times. The package also provides utility functions for exponentially tilted primary event distributions. All functions support any mixture of primary and secondary censoring intervals of varying widths, as well as heterogeneous observation times across observations. The package is fully documented and includes examples in the vignettes. All functionality is tested for correctness and performance. It is available on CRAN and GitHub [@primarycensored; @primarycensoredgithub].

#### Stan implementation

To support Bayesian modelling, we developed Stan implementations of the primary censored delay distribution framework [@stan]. These implementations include log probability mass functions for integrating into observation models. The Stan interface maintains compatibility with the R interface while following Stan's syntactic requirements. We provide a complete Stan model for estimating distribution parameters from double-censored data with within-chain parallelisation for improved efficiency [@cmdstanr]. This model supports all distributions available in Stan and serves as a template that users can extend for more complex modelling scenarios. The implementation includes helper functions that facilitate integrating the Stan code into existing workflows through file generation or direct inclusion via Stan's include mechanism. All Stan code is fully tested against the R implementation and documented as a website [@primarycensoredstan]. We provide a vignette demonstrating how to use the Stan tools and another vignette with examples of how to fit Stan models to simulated data [@primarycensoredstantools; @primarycensoredstanexamples].

#### fitdistrplus extensions

We extended the `fitdistrplus` package to handle double-censored data through a wrapper function that enables maximum likelihood estimation of delay distribution parameters without complex dependencies [@fitdistrplus]. This integration again accounts for primary event censoring, secondary event censoring, and right truncation simultaneously. Similar to the core R functionality, the extension supports arbitrary distributions, mixtures of censoring intervals, and heterogeneous observation times. The wrapper accepts data frames with columns specifying bounds for observed delays, censoring window widths, and maximum observable times. We provide a vignette with examples of how to use the wrapper [@primarycensoredfitdistrplus].

### Evaluation design

#### Simulated datasets
- Three distributions with comparable means but varied shapes:
  * Gamma (moderate variance)
  * Lognormal (higher variance with heavier tail)
  * Burr (heaviest tail)
- Three truncation scenarios:
  * No truncation (retrospective scenario)
  * Moderate truncation (realistic real-time scenario)
  * Severe truncation (challenging real-time scenario)
- Consistent primary and secondary censoring windows across all scenarios but varying between individuals. Ranging from 1 day to 4 days for each primary and secondary event.
- Total of 9 reference datasets (3 distributions × 3 truncation levels)
- Visualization approach: panel plots with distributions along columns and truncation scenarios along rows
- Simulate for a 10000 individuals

#### Numerical validation
- Comparison of analytical, numerical and Monte Carlo solutions at PMF stage
- Look at different sample sizes.
- Visualise comparison of different methods
- Relative runtime metrics

#### Parameter recovery
- Stan-based estimation protocol
- fitdistrplus-based estimation protocol
- Comparison with naive model approaches
- Look at different sample sizes.
- Visualisation of parameter recovery

### Case study
- Sierra Leone Ebola outbreak data
- Data description and preprocessing
- Analysis approach
- Comparison protocol with Park et al. results
- Visualisation of case study results
### Implementation details
- Software tools and versions
- Hardware specifications
- Reproducibility information

## Results

### Numerical validation results
- Accuracy comparison across scenarios and sample sizes
- Runtime performance comparison

### Parameter recovery results
- Stan-based estimation results across all scenarios and sample sizes
- fitdistrplus-based estimation results
- Comparison with naive models in both
- Need to have a main figure with a single sample size and then duplicates for different sample sizes in the SI for both.

### Case study results
- Estimated parameters and key findings
- Comparison with previous estimates from Park et al.
- Performance advantages demonstrated

## Discussion

### Summary

### Strengths and limitations

### Comparison with existing methods

### Future work

### Conclusions

## References

## Supporting information

### Detailed analytical solutions

#### General framework for analytical solutions
- Explanation of when analytical solutions are possible
- Role of partial expectation in deriving solutions

#### Solutions for exponentially tilted primary event times
- Complete derivation of equation for F_CP
- Limiting case for uniform distribution

#### Gamma distribution
- Full derivation of partial expectation
- Complete survival function and PMF formulations

#### Lognormal distribution
- Full derivation of partial expectation
- Complete survival function and PMF formulations

#### Weibull distribution
- Full derivation of partial expectation 
- Complete survival function and PMF formulations

### Mathematical details of the naive comparison model
- Derivation of the model used for comparison
- Explanation of the limitations and assumptions
- Implementation details


### Connection to other approaches
- Connection to Park et al.
- Connection to Reich et al. 
- Connection to Cori et al.

### Extended numerical validation results
- Detailed accuracy metrics across all distributions and sample sizes
- Additional visualizations

### Extended parameter recovery results

#### Stan-based estimation
- Full results across all sample sizes
- Detailed convergence diagnostics
- Additional parameter visualizations

#### fitdistrplus-based estimation
- Full results across all sample sizes
- Convergence and optimization details

#### Comparison with naive models
- Complete comparative analysis
- Additional error metrics

### Extended case study results
- Complete parameter visualizations
- Additional comparative outputs
